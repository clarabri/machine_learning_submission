{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88150644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Using cached absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Using cached flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.7.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (25.0)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow)\n",
      "  Using cached protobuf-6.33.2-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Using cached termcolor-3.2.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (4.15.0)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Using cached wrapt-2.0.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Using cached grpcio-1.76.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Using cached tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow)\n",
      "  Using cached keras-3.12.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/codespace/.local/lib/python3.12/site-packages (from tensorflow) (2.3.4)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Using cached h5py-3.15.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Using cached ml_dtypes-0.5.4-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached markdown-3.10-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: pillow in /home/codespace/.local/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (12.0.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached werkzeug-3.1.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rich (from keras>=3.10.0->tensorflow)\n",
      "  Using cached rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow)\n",
      "  Using cached namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow)\n",
      "  Using cached optree-0.18.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (34 kB)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /home/codespace/.local/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.10.0->tensorflow)\n",
      "  Using cached markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/codespace/.local/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (620.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m620.7/620.7 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m  \u001b[33m0:00:12\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.76.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.4-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.7.0-py3-none-any.whl (22 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading h5py-3.15.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.12.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading markdown-3.10-py3-none-any.whl (107 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-6.33.2-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
      "Downloading termcolor-3.2.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading werkzeug-3.1.4-py3-none-any.whl (224 kB)\n",
      "Downloading wrapt-2.0.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (121 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.18.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (408 kB)\n",
      "Downloading rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, werkzeug, termcolor, tensorboard-data-server, protobuf, optree, opt_einsum, ml_dtypes, mdurl, markdown, h5py, grpcio, google_pasta, gast, absl-py, tensorboard, markdown-it-py, astunparse, rich, keras, tensorflow\n",
      "\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/25\u001b[0m [wheel]ng]\u001b[33m  WARNING: The script wheel is installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/25\u001b[0m [markdown]m]\u001b[33m  WARNING: The script markdown_py is installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m19/25\u001b[0m [tensorboard]\u001b[33m  WARNING: The script tensorboard is installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m20/25\u001b[0m [markdown-it-py]\u001b[33m  WARNING: The script markdown-it is installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m24/25\u001b[0m [tensorflow]\u001b[33m  WARNING: The scripts import_pb_to_tensorboard, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert and toco are installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25/25\u001b[0m [tensorflow]5\u001b[0m [tensorflow]\n",
      "\u001b[1A\u001b[2KSuccessfully installed absl-py-2.3.1 astunparse-1.6.3 flatbuffers-25.9.23 gast-0.7.0 google_pasta-0.2.0 grpcio-1.76.0 h5py-3.15.1 keras-3.12.0 libclang-18.1.1 markdown-3.10 markdown-it-py-4.0.0 mdurl-0.1.2 ml_dtypes-0.5.4 namex-0.1.0 opt_einsum-3.4.0 optree-0.18.0 protobuf-6.33.2 rich-14.2.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.2.0 werkzeug-3.1.4 wheel-0.45.1 wrapt-2.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-11 13:25:33.295885: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-12-11 13:25:33.331060: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-11 13:25:34.688134: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-11 13:25:39.755368: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-11 13:25:39.756379: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%pip install tensorflow\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f0a69bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Daten laden\n",
    "train_data = pd.read_csv('../0_DataPreparation/data/train_data.csv')\n",
    "val_data = pd.read_csv('../0_DataPreparation/data/validation_data.csv')\n",
    "test_data = pd.read_csv('../0_DataPreparation/data/test_data.csv')\n",
    "\n",
    "# Kategorische Variable und Ziel definieren\n",
    "X_train_cat = train_data[['Warengruppe']]\n",
    "y_train = train_data['Umsatz'].values\n",
    "\n",
    "X_val_cat = val_data[['Warengruppe']]\n",
    "y_val = val_data['Umsatz'].values\n",
    "\n",
    "X_test_cat = test_data[['Warengruppe']]\n",
    "y_test = test_data['Umsatz'].values\n",
    "\n",
    "# One-Hot-Encoding\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "X_train = encoder.fit_transform(X_train_cat)\n",
    "X_val = encoder.transform(X_val_cat)\n",
    "X_test = encoder.transform(X_test_cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f2d2482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-11 13:34:08.822782: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 65366.4414 - mae: 208.7563 - val_loss: 55058.3555 - val_mae: 195.4039\n",
      "Epoch 2/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 65178.2266 - mae: 208.3053 - val_loss: 54882.4258 - val_mae: 194.9549\n",
      "Epoch 3/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 64990.8945 - mae: 207.8564 - val_loss: 54707.0234 - val_mae: 194.5063\n",
      "Epoch 4/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 64803.7188 - mae: 207.4093 - val_loss: 54532.0664 - val_mae: 194.0577\n",
      "Epoch 5/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 64616.7891 - mae: 206.9590 - val_loss: 54357.4648 - val_mae: 193.6089\n",
      "Epoch 6/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 64430.6094 - mae: 206.5112 - val_loss: 54183.3086 - val_mae: 193.1608\n",
      "Epoch 7/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 64244.9297 - mae: 206.0637 - val_loss: 54009.9961 - val_mae: 192.7137\n",
      "Epoch 8/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 64059.5859 - mae: 205.6168 - val_loss: 53836.7578 - val_mae: 192.2660\n",
      "Epoch 9/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 63874.8789 - mae: 205.1681 - val_loss: 53663.9375 - val_mae: 191.8184\n",
      "Epoch 10/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63691.2305 - mae: 204.7234 - val_loss: 53492.5859 - val_mae: 191.3729\n",
      "Epoch 11/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 63508.1094 - mae: 204.2763 - val_loss: 53321.3164 - val_mae: 190.9266\n",
      "Epoch 12/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 63325.2461 - mae: 203.8310 - val_loss: 53150.6797 - val_mae: 190.4813\n",
      "Epoch 13/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 63143.2305 - mae: 203.3857 - val_loss: 52980.4102 - val_mae: 190.0359\n",
      "Epoch 14/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 62961.5312 - mae: 202.9398 - val_loss: 52810.8125 - val_mae: 189.5907\n",
      "Epoch 15/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 62780.0586 - mae: 202.4955 - val_loss: 52641.4609 - val_mae: 189.1458\n",
      "Epoch 16/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 62599.0117 - mae: 202.0500 - val_loss: 52472.1953 - val_mae: 188.7000\n",
      "Epoch 17/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 62418.5977 - mae: 201.6054 - val_loss: 52303.8555 - val_mae: 188.2556\n",
      "Epoch 18/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 62238.5312 - mae: 201.1606 - val_loss: 52135.7773 - val_mae: 187.8109\n",
      "Epoch 19/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 62058.8867 - mae: 200.7156 - val_loss: 51967.8164 - val_mae: 187.3658\n",
      "Epoch 20/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61879.6484 - mae: 200.2702 - val_loss: 51800.8672 - val_mae: 186.9220\n",
      "Epoch 21/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61700.9062 - mae: 199.8246 - val_loss: 51634.1211 - val_mae: 186.4780\n",
      "Epoch 22/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61522.9023 - mae: 199.3814 - val_loss: 51467.7344 - val_mae: 186.0340\n",
      "Epoch 23/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61345.1367 - mae: 198.9381 - val_loss: 51302.1836 - val_mae: 185.5906\n",
      "Epoch 24/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 61167.3555 - mae: 198.4931 - val_loss: 51136.3828 - val_mae: 185.1463\n",
      "Epoch 25/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60990.1758 - mae: 198.0482 - val_loss: 50971.1602 - val_mae: 184.7020\n",
      "Epoch 26/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60813.3633 - mae: 197.6038 - val_loss: 50805.9492 - val_mae: 184.2574\n",
      "Epoch 27/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60636.9023 - mae: 197.1600 - val_loss: 50641.5234 - val_mae: 183.8136\n",
      "Epoch 28/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 60461.0352 - mae: 196.7159 - val_loss: 50477.9453 - val_mae: 183.3708\n",
      "Epoch 29/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 60285.4219 - mae: 196.2722 - val_loss: 50314.2812 - val_mae: 182.9269\n",
      "Epoch 30/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 60110.2109 - mae: 195.8276 - val_loss: 50150.9688 - val_mae: 182.4827\n",
      "Epoch 31/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59935.7773 - mae: 195.3851 - val_loss: 49988.4062 - val_mae: 182.0394\n",
      "Epoch 32/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59761.5195 - mae: 194.9406 - val_loss: 49826.3242 - val_mae: 181.5962\n",
      "Epoch 33/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 59587.6445 - mae: 194.4958 - val_loss: 49664.2734 - val_mae: 181.1529\n",
      "Epoch 34/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 59413.9453 - mae: 194.0529 - val_loss: 49502.3984 - val_mae: 180.7086\n",
      "Epoch 35/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 59240.5078 - mae: 193.6076 - val_loss: 49341.3203 - val_mae: 180.2654\n",
      "Epoch 36/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 59067.6250 - mae: 193.1633 - val_loss: 49180.2539 - val_mae: 179.8217\n",
      "Epoch 37/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58895.1602 - mae: 192.7213 - val_loss: 49020.0273 - val_mae: 179.3787\n",
      "Epoch 38/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 58723.3281 - mae: 192.2766 - val_loss: 48859.8047 - val_mae: 178.9348\n",
      "Epoch 39/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58552.1914 - mae: 191.8334 - val_loss: 48700.8711 - val_mae: 178.4930\n",
      "Epoch 40/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58381.2773 - mae: 191.3920 - val_loss: 48541.5156 - val_mae: 178.0494\n",
      "Epoch 41/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58210.7617 - mae: 190.9481 - val_loss: 48383.2656 - val_mae: 177.6074\n",
      "Epoch 42/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 58040.6367 - mae: 190.5057 - val_loss: 48225.2383 - val_mae: 177.1648\n",
      "Epoch 43/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57870.7031 - mae: 190.0607 - val_loss: 48067.1641 - val_mae: 176.7215\n",
      "Epoch 44/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 57700.9805 - mae: 189.6181 - val_loss: 47909.4961 - val_mae: 176.2782\n",
      "Epoch 45/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57532.2734 - mae: 189.1765 - val_loss: 47752.7695 - val_mae: 175.8359\n",
      "Epoch 46/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57363.8867 - mae: 188.7335 - val_loss: 47596.2617 - val_mae: 175.3934\n",
      "Epoch 47/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57195.6484 - mae: 188.2901 - val_loss: 47439.8164 - val_mae: 174.9503\n",
      "Epoch 48/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57027.6250 - mae: 187.8481 - val_loss: 47283.8008 - val_mae: 174.5072\n",
      "Epoch 49/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 56860.2578 - mae: 187.4046 - val_loss: 47128.4492 - val_mae: 174.0651\n",
      "Epoch 50/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56693.0977 - mae: 186.9627 - val_loss: 46973.1367 - val_mae: 173.6222\n",
      "Epoch 51/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56526.4844 - mae: 186.5200 - val_loss: 46818.6719 - val_mae: 173.1801\n",
      "Epoch 52/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 56360.3633 - mae: 186.0779 - val_loss: 46664.4609 - val_mae: 172.7381\n",
      "Epoch 53/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 56194.4688 - mae: 185.6366 - val_loss: 46510.1953 - val_mae: 172.2952\n",
      "Epoch 54/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 56029.1914 - mae: 185.1941 - val_loss: 46356.9375 - val_mae: 171.8537\n",
      "Epoch 55/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55864.5078 - mae: 184.7509 - val_loss: 46204.1875 - val_mae: 171.4120\n",
      "Epoch 56/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55700.1250 - mae: 184.3110 - val_loss: 46051.7344 - val_mae: 170.9706\n",
      "Epoch 57/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55536.0859 - mae: 183.8707 - val_loss: 45899.7734 - val_mae: 170.5290\n",
      "Epoch 58/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 55372.4883 - mae: 183.4292 - val_loss: 45747.9688 - val_mae: 170.0869\n",
      "Epoch 59/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 55209.0977 - mae: 182.9886 - val_loss: 45596.5938 - val_mae: 169.6453\n",
      "Epoch 60/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 55045.9609 - mae: 182.5486 - val_loss: 45445.5898 - val_mae: 169.2036\n",
      "Epoch 61/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 54883.1445 - mae: 182.1064 - val_loss: 45294.6250 - val_mae: 168.7613\n",
      "Epoch 62/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54721.0703 - mae: 181.6654 - val_loss: 45144.4922 - val_mae: 168.3198\n",
      "Epoch 63/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 54559.2422 - mae: 181.2242 - val_loss: 44994.8828 - val_mae: 167.8786\n",
      "Epoch 64/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54397.8398 - mae: 180.7834 - val_loss: 44845.2070 - val_mae: 167.4375\n",
      "Epoch 65/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 54237.0234 - mae: 180.3438 - val_loss: 44696.5938 - val_mae: 166.9975\n",
      "Epoch 66/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54076.3984 - mae: 179.9017 - val_loss: 44547.9375 - val_mae: 166.5565\n",
      "Epoch 67/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53916.5352 - mae: 179.4621 - val_loss: 44399.8828 - val_mae: 166.1165\n",
      "Epoch 68/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 53756.8789 - mae: 179.0224 - val_loss: 44252.1641 - val_mae: 165.6765\n",
      "Epoch 69/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 53597.9648 - mae: 178.5826 - val_loss: 44105.3164 - val_mae: 165.2371\n",
      "Epoch 70/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53439.3945 - mae: 178.1452 - val_loss: 43958.5938 - val_mae: 164.7976\n",
      "Epoch 71/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53281.0820 - mae: 177.7034 - val_loss: 43812.0977 - val_mae: 164.3576\n",
      "Epoch 72/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 53123.2891 - mae: 177.2663 - val_loss: 43666.3281 - val_mae: 163.9187\n",
      "Epoch 73/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 52966.1602 - mae: 176.8297 - val_loss: 43521.1875 - val_mae: 163.4802\n",
      "Epoch 74/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 52808.8984 - mae: 176.3882 - val_loss: 43375.2969 - val_mae: 163.0394\n",
      "Epoch 75/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 52652.2031 - mae: 175.9523 - val_loss: 43230.8516 - val_mae: 162.6013\n",
      "Epoch 76/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 52495.8711 - mae: 175.5135 - val_loss: 43086.3438 - val_mae: 162.1627\n",
      "Epoch 77/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 52340.2031 - mae: 175.0758 - val_loss: 42942.7031 - val_mae: 161.7251\n",
      "Epoch 78/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 52185.0117 - mae: 174.6395 - val_loss: 42799.5898 - val_mae: 161.2883\n",
      "Epoch 79/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 52029.6641 - mae: 174.2012 - val_loss: 42655.9922 - val_mae: 160.8495\n",
      "Epoch 80/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 51875.1562 - mae: 173.7661 - val_loss: 42513.7422 - val_mae: 160.4125\n",
      "Epoch 81/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 51721.0586 - mae: 173.3289 - val_loss: 42371.2070 - val_mae: 159.9742\n",
      "Epoch 82/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 51567.1953 - mae: 172.8923 - val_loss: 42229.4414 - val_mae: 159.5366\n",
      "Epoch 83/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 51413.5039 - mae: 172.4550 - val_loss: 42087.4609 - val_mae: 159.0975\n",
      "Epoch 84/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 51260.5273 - mae: 172.0197 - val_loss: 41946.3672 - val_mae: 158.6596\n",
      "Epoch 85/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 51107.9180 - mae: 171.5833 - val_loss: 41805.8281 - val_mae: 158.2226\n",
      "Epoch 86/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 50955.3477 - mae: 171.1468 - val_loss: 41665.0938 - val_mae: 157.7843\n",
      "Epoch 87/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 50803.0078 - mae: 170.7122 - val_loss: 41524.9570 - val_mae: 157.3468\n",
      "Epoch 88/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 50651.0273 - mae: 170.2771 - val_loss: 41384.9609 - val_mae: 156.9097\n",
      "Epoch 89/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 50499.5859 - mae: 169.8412 - val_loss: 41245.4219 - val_mae: 156.4733\n",
      "Epoch 90/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 50348.7656 - mae: 169.4082 - val_loss: 41106.6719 - val_mae: 156.0380\n",
      "Epoch 91/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 50198.6719 - mae: 168.9725 - val_loss: 40968.4648 - val_mae: 155.6037\n",
      "Epoch 92/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 50048.8086 - mae: 168.5399 - val_loss: 40830.3359 - val_mae: 155.1687\n",
      "Epoch 93/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 49899.4297 - mae: 168.1077 - val_loss: 40692.8633 - val_mae: 154.7345\n",
      "Epoch 94/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 49750.3750 - mae: 167.6752 - val_loss: 40555.4727 - val_mae: 154.3001\n",
      "Epoch 95/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 49601.7539 - mae: 167.2442 - val_loss: 40419.0508 - val_mae: 153.8670\n",
      "Epoch 96/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 49452.9531 - mae: 166.8104 - val_loss: 40282.3477 - val_mae: 153.4331\n",
      "Epoch 97/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 49305.3125 - mae: 166.3805 - val_loss: 40146.6523 - val_mae: 153.0009\n",
      "Epoch 98/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 49158.2188 - mae: 165.9483 - val_loss: 40011.1680 - val_mae: 152.5695\n",
      "Epoch 99/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 49011.4453 - mae: 165.5197 - val_loss: 39876.2578 - val_mae: 152.1391\n",
      "Epoch 100/100\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 48864.8047 - mae: 165.0914 - val_loss: 39741.7266 - val_mae: 151.7098\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"model = tf.keras.Sequential([\\n    tf.keras.layers.Input(shape=(X_train.shape[1],)),\\n    tf.keras.layers.Dense(32, activation='relu'),\\n    tf.keras.layers.Dense(16, activation='relu'),\\n    tf.keras.layers.Dense(1)  # Output ohne Aktivierung für Regression\\n])\\n\\nmodel.compile(optimizer='adam', loss='mse', metrics=['mae'])\\n\\nhistory = model.fit(\\n    X_train, y_train,\\n    validation_data=(X_val, y_val),\\n    epochs=50,\\n    verbose=1\\n)\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Einfaches lineares Modell (entspricht OLS)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(1)  # Lineare Regression\n",
    "])\n",
    "\n",
    "# Kompilieren\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Trainieren mit expliziter Validierung\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "##Nicht linear mit Aktivierungsfunktion\n",
    "'''model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)  # Output ohne Aktivierung für Regression\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50,\n",
    "    verbose=1\n",
    ")\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee614497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Vorhersagen auf Testdaten\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "plt.scatter(y_test, y_pred.reshape(-1))\n",
    "plt.xlabel(\"Ec\n",
    "plt.ylabel(\"Vorhergesagte Werte\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
